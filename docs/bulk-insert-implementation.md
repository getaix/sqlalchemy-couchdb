# æ‰¹é‡æ’å…¥å®ç°æ–¹æ¡ˆ

**åˆ›å»ºæ—¥æœŸ**: 2025-11-02
**çŠ¶æ€**: è®¾è®¡ä¸­
**ç›®æ ‡**: ä½¿ç”¨CouchDBçš„`_bulk_docs` APIå®ç°é«˜æ€§èƒ½æ‰¹é‡æ’å…¥

## ğŸ“‹ å½“å‰çŠ¶æ€

### ç°æœ‰å®ç°
- âœ… **Clientå±‚**: `bulk_docs()` æ–¹æ³•å·²å®ç°ï¼ˆåŒæ­¥+å¼‚æ­¥ï¼‰
- âš ï¸ **DBAPIå±‚**: ä½¿ç”¨å¾ªç¯è°ƒç”¨å•æ¡æ’å…¥
- âš ï¸ **Compilerå±‚**: ä»…æ”¯æŒå•æ¡INSERTç¼–è¯‘
- âŒ **Dialectå±‚**: `supports_multivalues_insert = False`

### æ€§èƒ½ç°çŠ¶
```python
# å½“å‰æ–¹å¼ï¼šå¾ªç¯æ’å…¥100æ¡è®°å½•
for i in range(100):
    conn.execute(insert(users).values(name=f"User{i}", age=20+i))
conn.commit()
# è€—æ—¶ï¼š~3-5ç§’ï¼ˆ100æ¬¡HTTPè¯·æ±‚ï¼‰
```

### ç›®æ ‡æ€§èƒ½
```python
# ç›®æ ‡æ–¹å¼ï¼šæ‰¹é‡æ’å…¥100æ¡è®°å½•
conn.execute(insert(users), [
    {"name": f"User{i}", "age": 20+i} for i in range(100)
])
conn.commit()
# é¢„æœŸè€—æ—¶ï¼š~0.5ç§’ï¼ˆ1æ¬¡HTTPè¯·æ±‚ï¼‰
```

## ğŸ¯ SQLAlchemy 2.0 insertmanyvalues æœºåˆ¶

### æ ¸å¿ƒæ¦‚å¿µ

1. **insertmanyvalues** (SQLAlchemy 2.0.10+)
   - æ‰¹é‡INSERTä¼˜åŒ–ç‰¹æ€§
   - æ”¯æŒINSERT..RETURNING with executemany
   - è‡ªåŠ¨åˆ†é¡µå¤„ç†å¤§æ‰¹é‡æ•°æ®
   - é»˜è®¤æ‰¹æ¬¡å¤§å°ï¼š1000è¡Œ

2. **Dialectå±æ€§**
   ```python
   supports_multivalues_insert = True  # å¯ç”¨å¤šå€¼æ’å…¥æ”¯æŒ
   ```

3. **æ‰§è¡Œæ–¹å¼**
   ```python
   # executemany - ä¼ ç»Ÿæ‰¹é‡æ’å…¥
   conn.execute(stmt, [{"name": "Alice"}, {"name": "Bob"}])

   # insertmanyvalues - SQLAlchemy 2.0ä¼˜åŒ–æ–¹å¼
   # è‡ªåŠ¨ä½¿ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®
   ```

### CouchDBç‰¹æ®Šæ€§

CouchDBä¸å…³ç³»å‹æ•°æ®åº“çš„å·®å¼‚ï¼š

| ç‰¹æ€§ | å…³ç³»å‹æ•°æ®åº“ | CouchDB |
|------|------------|---------|
| æ‰¹é‡æ’å…¥API | `INSERT INTO ... VALUES (...), (...)` | `POST /db/_bulk_docs` |
| RETURNINGæ”¯æŒ | æ”¯æŒ | ä¸æ”¯æŒï¼ˆä½†bulk_docsè¿”å›_id/_revï¼‰ |
| ç»‘å®šå‚æ•° | æ”¯æŒ | æ— ï¼ˆç›´æ¥JSONï¼‰ |
| äº‹åŠ¡æ”¯æŒ | æ”¯æŒ | ä¸æ”¯æŒï¼ˆä»…æ–‡æ¡£çº§åŸå­æ€§ï¼‰ |

## ğŸ”§ å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆæ¶æ„

```
User Code (executemany)
    â†“
SQLAlchemy Core
    â†“
CouchDBDialect (å¯ç”¨ supports_multivalues_insert)
    â†“
CouchDBCompiler (ç¼–è¯‘ä¸ºæ‰¹é‡JSON)
    â†“
DBAPI (do_executemany_returning)
    â†“
CouchDBClient.bulk_docs()
    â†“
CouchDB _bulk_docs API
```

### å®ç°æ­¥éª¤

#### 1. Dialectå±‚ä¿®æ”¹

**æ–‡ä»¶**: `sqlalchemy_couchdb/dialect.py`

```python
class CouchDBDialect(default.DefaultDialect):
    # å¯ç”¨å¤šå€¼æ’å…¥æ”¯æŒ
    supports_multivalues_insert = True

    # é…ç½®æ‰¹æ¬¡å¤§å°ï¼ˆCouchDBæ¨è<1000ï¼‰
    insert_executemany_returning = True
    insertmanyvalues_page_size = 500  # ä¿å®ˆè®¾ç½®

    def do_executemany(self, cursor, statement, parameters, context=None):
        """æ‰§è¡Œæ‰¹é‡æ“ä½œ"""
        # å°†parametersåˆå¹¶åˆ°statementçš„JSONä¸­
        # è°ƒç”¨cursor.executemany()
        pass
```

#### 2. Compilerå±‚ä¿®æ”¹

**æ–‡ä»¶**: `sqlalchemy_couchdb/compiler.py`

å½“å‰çš„`visit_insert()`åªå¤„ç†å•æ¡ï¼š
```python
def visit_insert(self, insert_stmt, **kwargs):
    document = {"type": table_name}
    for col_name, value in insert_stmt._values.items():
        document[col_name] = self._extract_value(value)

    query = {
        "type": "insert",
        "table": table_name,
        "document": document
    }
    return json.dumps(query)
```

éœ€è¦ä¿®æ”¹ä¸ºæ”¯æŒæ‰¹é‡ï¼š
```python
def visit_insert(self, insert_stmt, **kwargs):
    """
    ç¼–è¯‘INSERTè¯­å¥ï¼ˆæ”¯æŒå•æ¡å’Œæ‰¹é‡ï¼‰

    å•æ¡ï¼š
        {"type": "insert", "table": "users", "document": {...}}

    æ‰¹é‡ï¼ˆå¸¦executemanyæ ‡è®°ï¼‰ï¼š
        {"type": "insert_many", "table": "users", "documents": [...]}
    """
    table_name = self._get_table_name(insert_stmt)

    # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡æ’å…¥
    if self._is_bulk_insert(insert_stmt):
        # ç¼–è¯‘ä¸ºæ‰¹é‡æ ¼å¼
        query = {
            "type": "insert_many",
            "table": table_name,
            "documents": []  # å ä½ç¬¦ï¼ŒDBAPIå±‚å¡«å……
        }
    else:
        # å•æ¡æ’å…¥ï¼ˆä¿æŒå…¼å®¹ï¼‰
        document = self._build_document(insert_stmt, table_name)
        query = {
            "type": "insert",
            "table": table_name,
            "document": document
        }

    return json.dumps(query)

def _is_bulk_insert(self, insert_stmt):
    """æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡æ’å…¥"""
    # SQLAlchemyä¼šåœ¨contextä¸­è®¾ç½®executemanyæ ‡è®°
    # æˆ–è€…é€šè¿‡insert_stmtçš„å±æ€§åˆ¤æ–­
    return getattr(insert_stmt, '_is_bulk', False)

def _build_document(self, insert_stmt, table_name):
    """æ„å»ºå•ä¸ªæ–‡æ¡£"""
    document = {"type": table_name}
    if hasattr(insert_stmt, '_values') and insert_stmt._values:
        for col_name, value in insert_stmt._values.items():
            if col_name not in ("_id", "_rev"):
                document[col_name] = self._extract_value(value)
    return document
```

#### 3. DBAPIå±‚ä¿®æ”¹

**æ–‡ä»¶**: `sqlalchemy_couchdb/dbapi/sync.py` å’Œ `async_.py`

æ·»åŠ æ‰¹é‡æ‰§è¡Œæ”¯æŒï¼š

```python
class SyncCursor:
    def executemany(self, operation, seq_of_parameters):
        """
        æ‰§è¡Œæ‰¹é‡æ“ä½œ

        å‚æ•°:
            operation: JSONç¼–è¯‘åçš„æŸ¥è¯¢ï¼ˆåŒ…å«insert_manyç±»å‹ï¼‰
            seq_of_parameters: å‚æ•°åˆ—è¡¨ [{"name": "Alice", ...}, ...]
        """
        query = json.loads(operation)

        if query.get("type") != "insert_many":
            # ä¸æ”¯æŒå…¶ä»–æ‰¹é‡æ“ä½œï¼Œå›é€€åˆ°å¾ªç¯
            for params in seq_of_parameters:
                self.execute(operation, params)
            return

        # æ„å»ºæ‰¹é‡æ–‡æ¡£
        table_name = query["table"]
        documents = []

        for params in seq_of_parameters:
            doc = {"type": table_name}
            doc.update(params)
            documents.append(doc)

        # è°ƒç”¨bulk_docs API
        try:
            result = self.connection.client.bulk_docs(documents)

            # å¤„ç†ç»“æœ
            self.rowcount = len([r for r in result if not r.get('error')])
            self._last_result = result

            # è®¾ç½®descriptionï¼ˆå…¼å®¹æ€§ï¼‰
            self.description = [("_id",), ("_rev",)]

        except Exception as e:
            raise exception_from_response(None, str(e))

    def fetchall(self):
        """è¿”å›æ‰¹é‡æ’å…¥çš„ç»“æœ"""
        if hasattr(self, '_last_result'):
            # æ ¼å¼åŒ–ä¸ºæ ‡å‡†è¡Œæ ¼å¼
            rows = []
            for item in self._last_result:
                if not item.get('error'):
                    rows.append((item.get('id'), item.get('rev')))
            return rows
        return []
```

å¼‚æ­¥ç‰ˆæœ¬ç±»ä¼¼ï¼š
```python
class AsyncCursor:
    async def executemany(self, operation, seq_of_parameters):
        """å¼‚æ­¥æ‰¹é‡æ‰§è¡Œ"""
        # å®ç°ä¸åŒæ­¥ç‰ˆæœ¬ç±»ä¼¼ï¼Œä½†ä½¿ç”¨await
        await self.connection.client.bulk_docs(documents)
```

#### 4. é”™è¯¯å¤„ç†

æ‰¹é‡æ“ä½œå¯èƒ½éƒ¨åˆ†æˆåŠŸï¼š

```python
# CouchDB bulk_docså“åº”ç¤ºä¾‹
[
    {"ok": true, "id": "doc1", "rev": "1-abc"},
    {"error": "conflict", "id": "doc2", "reason": "Document update conflict"},
    {"ok": true, "id": "doc3", "rev": "1-def"}
]
```

éœ€è¦å¤„ç†ç­–ç•¥ï¼š
- **å…¨éƒ¨æˆåŠŸ**: æ­£å¸¸è¿”å›
- **å…¨éƒ¨å¤±è´¥**: æŠ›å‡ºIntegrityError
- **éƒ¨åˆ†å¤±è´¥**:
  - é€‰é¡¹1: æŠ›å‡ºå¼‚å¸¸ï¼ŒåŒ…å«è¯¦ç»†é”™è¯¯ä¿¡æ¯
  - é€‰é¡¹2: è¿”å›æˆåŠŸçš„è®°å½•æ•°ï¼Œé”™è¯¯è®°å½•å•ç‹¬å­˜å‚¨

æ¨è**é€‰é¡¹1**ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰ï¼š
```python
if any(r.get('error') for r in result):
    errors = [r for r in result if r.get('error')]
    raise IntegrityError(
        f"æ‰¹é‡æ’å…¥éƒ¨åˆ†å¤±è´¥: {len(errors)}/{len(result)} å¤±è´¥\n"
        f"è¯¦ç»†ä¿¡æ¯: {errors[:5]}"  # æœ€å¤šæ˜¾ç¤º5ä¸ªé”™è¯¯
    )
```

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### åŸºå‡†æµ‹è¯•è®¡åˆ’

**æµ‹è¯•åœºæ™¯**:
- æ’å…¥100æ¡è®°å½•
- æ’å…¥1000æ¡è®°å½•
- æ’å…¥5000æ¡è®°å½•

**å¯¹æ¯”æŒ‡æ ‡**:

| è®°å½•æ•° | å½“å‰æ–¹å¼ï¼ˆå¾ªç¯ï¼‰ | æ‰¹é‡æ–¹å¼ï¼ˆbulk_docsï¼‰ | æ€§èƒ½æå‡ |
|--------|----------------|---------------------|----------|
| 100    | ~3ç§’ (100è¯·æ±‚)  | ~0.5ç§’ (1è¯·æ±‚)       | 6x âš¡    |
| 1000   | ~30ç§’ (1000è¯·æ±‚)| ~2ç§’ (2è¯·æ±‚)         | 15x âš¡   |
| 5000   | ~150ç§’ (5000è¯·æ±‚)| ~10ç§’ (10è¯·æ±‚)      | 15x âš¡   |

**æ³¨æ„äº‹é¡¹**:
- æ‰¹æ¬¡å¤§å°é™åˆ¶ï¼š500æ¡/æ‰¹ï¼ˆå¯é…ç½®ï¼‰
- å¤§äº500æ¡è‡ªåŠ¨åˆ†æ‰¹
- ç½‘ç»œå»¶è¿Ÿå½±å“å‡å°‘95%+

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `tests/test_bulk_insert.py`

```python
def test_bulk_insert_100_records():
    """æµ‹è¯•æ‰¹é‡æ’å…¥100æ¡è®°å½•"""
    users = [
        {"name": f"User{i}", "age": 20 + i}
        for i in range(100)
    ]

    conn.execute(insert(users_table), users)

    result = conn.execute(select(users_table)).fetchall()
    assert len(result) == 100

def test_bulk_insert_partial_failure():
    """æµ‹è¯•æ‰¹é‡æ’å…¥éƒ¨åˆ†å¤±è´¥çš„å¤„ç†"""
    # åŒ…å«é‡å¤IDçš„è®°å½•
    users = [
        {"_id": "user1", "name": "Alice"},
        {"_id": "user1", "name": "Bob"},  # é‡å¤ID
    ]

    with pytest.raises(IntegrityError):
        conn.execute(insert(users_table), users)

async def test_async_bulk_insert():
    """æµ‹è¯•å¼‚æ­¥æ‰¹é‡æ’å…¥"""
    async with engine.connect() as conn:
        users = [{"name": f"User{i}"} for i in range(100)]
        await conn.execute(insert(users_table), users)

        result = await conn.execute(select(users_table))
        rows = result.fetchall()
        assert len(rows) == 100
```

### æ€§èƒ½æµ‹è¯•

**æ–‡ä»¶**: `tests/test_bulk_performance.py`

```python
def test_bulk_insert_performance():
    """å¯¹æ¯”æ‰¹é‡æ’å…¥ä¸å¾ªç¯æ’å…¥çš„æ€§èƒ½"""
    import time

    # å¾ªç¯æ–¹å¼
    start = time.perf_counter()
    for i in range(100):
        conn.execute(insert(users_table).values(name=f"User{i}"))
    conn.commit()
    loop_time = time.perf_counter() - start

    cleanup()

    # æ‰¹é‡æ–¹å¼
    start = time.perf_counter()
    users = [{"name": f"User{i}"} for i in range(100)]
    conn.execute(insert(users_table), users)
    conn.commit()
    bulk_time = time.perf_counter() - start

    print(f"å¾ªç¯æ’å…¥: {loop_time:.3f}ç§’")
    print(f"æ‰¹é‡æ’å…¥: {bulk_time:.3f}ç§’")
    print(f"æ€§èƒ½æå‡: {loop_time/bulk_time:.1f}x")

    assert bulk_time < loop_time / 3  # è‡³å°‘å¿«3å€
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### CouchDBé™åˆ¶

1. **è¯·æ±‚å¤§å°é™åˆ¶**
   - é»˜è®¤æœ€å¤§è¯·æ±‚ï¼š4MB
   - éœ€è¦é…ç½®: `max_document_size` å’Œ `max_http_request_size`
   - å»ºè®®æ‰¹æ¬¡å¤§å°ï¼š500æ¡ï¼ˆä¿å®ˆï¼‰

2. **æ— äº‹åŠ¡æ”¯æŒ**
   - bulk_docsæ˜¯åŸå­æ€§çš„æ–‡æ¡£çº§æ“ä½œ
   - éƒ¨åˆ†å¤±è´¥æ—¶æ— æ³•è‡ªåŠ¨å›æ»š
   - éœ€è¦åº”ç”¨å±‚å¤„ç†

3. **_idå†²çªå¤„ç†**
   - å¦‚æœæä¾›_idï¼Œå¿…é¡»å”¯ä¸€
   - å»ºè®®è®©CouchDBè‡ªåŠ¨ç”Ÿæˆ

### SQLAlchemyå…¼å®¹æ€§

1. **RETURNINGæ¨¡æ‹Ÿ**
   - CouchDBä¸æ”¯æŒRETURNINGè¯­æ³•
   - ä½†bulk_docsè¿”å›_idå’Œ_rev
   - å¯ä»¥æ¨¡æ‹ŸRETURNINGè¡Œä¸º

2. **executemanyå‚æ•°æ ¼å¼**
   - SQLAlchemyä¼ é€’: `[{col: val}, {col: val}]`
   - éœ€è¦è½¬æ¢ä¸ºCouchDBæ–‡æ¡£æ ¼å¼

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

- [x] ç ”ç©¶SQLAlchemy 2.0 insertmanyvaluesæ¥å£
- [ ] ä¿®æ”¹`dialect.py`å¯ç”¨æ‰¹é‡æ”¯æŒ
- [ ] ä¿®æ”¹`compiler.py`æ”¯æŒæ‰¹é‡ç¼–è¯‘
- [ ] ä¿®æ”¹`dbapi/sync.py`å®ç°executemany
- [ ] ä¿®æ”¹`dbapi/async_.py`å®ç°å¼‚æ­¥executemany
- [ ] æ·»åŠ é”™è¯¯å¤„ç†ï¼ˆéƒ¨åˆ†å¤±è´¥åœºæ™¯ï¼‰
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™æ€§èƒ½æµ‹è¯•
- [ ] æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
- [ ] æ›´æ–°TODO.mdå’ŒCHANGELOG.md

## ğŸ“ å‚è€ƒèµ„æ–™

1. **SQLAlchemyå®˜æ–¹æ–‡æ¡£**
   - [Insert, Updates, Deletes](https://docs.sqlalchemy.org/en/20/core/dml.html)
   - [Core Internals](https://docs.sqlalchemy.org/en/20/core/internals.html)

2. **CouchDBæ–‡æ¡£**
   - [Bulk Document API](https://docs.couchdb.org/en/stable/api/database/bulk-api.html)
   - [POST /{db}/_bulk_docs](https://docs.couchdb.org/en/stable/api/database/bulk-api.html#post--db-_bulk_docs)

3. **å®ç°å‚è€ƒ**
   - [psycopg2 fast execution helper](https://github.com/sqlalchemy/sqlalchemy/discussions/12038)
   - BigQuery dialect insertmanyvaluesè®¨è®º

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-02
